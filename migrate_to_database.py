#!/usr/bin/env python3
"""
CSVåˆ°SQLiteæ•°æ®åº“è¿ç§»å·¥å…·
å°†ç°æœ‰çš„CSVæ–‡ä»¶æ•°æ®è¿ç§»åˆ°SQLiteæ•°æ®åº“ä¸­
"""
import asyncio
import os
import csv
from pathlib import Path
from datetime import datetime

from database import DatabaseManager, BookRepository, SalesRepository

class DatabaseMigrator:
    """æ•°æ®åº“è¿ç§»å·¥å…·"""
    
    def __init__(self, db_path: str = "sellbook.db"):
        self.db_path = db_path
        self.db_manager = DatabaseManager(db_path)
        self.book_repo = BookRepository(db_path)
        self.sales_repo = SalesRepository(db_path)
        
        self.migration_stats = {
            'books_migrated': 0,
            'api_sales_migrated': 0,
            'sales_stats_migrated': 0,
            'errors': []
        }
    
    async def migrate_all(self):
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®è¿ç§»"""
        print("ğŸš€ å¼€å§‹CSVåˆ°SQLiteæ•°æ®åº“è¿ç§»")
        print("="*50)
        
        # 1. åˆå§‹åŒ–æ•°æ®åº“
        await self.init_database()
        
        # 2. è¿ç§»å„ç±»æ•°æ®
        await self.migrate_books_data()
        await self.migrate_api_sales_data()
        await self.migrate_sales_stats_data()
        
        # 3. éªŒè¯è¿ç§»ç»“æœ
        await self.verify_migration()
        
        # 4. æ‰“å°è¿ç§»æ‘˜è¦
        self.print_migration_summary()
        
        print("\nâœ… æ•°æ®è¿ç§»å®Œæˆ!")
    
    async def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“ç»“æ„"""
        print("ğŸ“Š åˆå§‹åŒ–æ•°æ®åº“ç»“æ„...")
        await self.db_manager.init_database()
        print("âœ… æ•°æ®åº“ç»“æ„åˆå§‹åŒ–å®Œæˆ")
    
    async def migrate_books_data(self):
        """è¿ç§»ä¹¦ç±åŸºç¡€æ•°æ® (books_data.csv)"""
        csv_file = "books_data.csv"
        print(f"\nğŸ“š è¿ç§»ä¹¦ç±æ•°æ®: {csv_file}")
        
        if not Path(csv_file).exists():
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
            return
        
        try:
            books_data = []
            
            with open(csv_file, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                
                for row_num, row in enumerate(reader, 1):
                    try:
                        book_data = {
                            'itemid': row.get('itemid', ''),
                            'shopid': row.get('shopid', ''),
                            'isbn': row.get('isbn', ''),
                            'title': row.get('title', ''),
                            'author': row.get('author', ''),
                            'publisher': row.get('publisher', ''),
                            'publish_year': row.get('publish_year', ''),
                            'quality': row.get('quality', ''),
                            'price': float(row.get('price', 0)) if row.get('price') else None,
                            'display_price': row.get('display_price', ''),
                            'book_url': row.get('book_url', ''),
                            'catnum': row.get('catnum', ''),
                            'userid': row.get('userid', ''),
                            'scraped_time': row.get('scraped_time', ''),
                            'scraped_shop_id': row.get('scraped_shop_id', ''),
                            'scraped_page': int(row.get('scraped_page', 0)) if row.get('scraped_page') else None,
                        }
                        books_data.append(book_data)
                        
                    except Exception as e:
                        error_msg = f"å¤„ç†ç¬¬{row_num}è¡Œæ•°æ®æ—¶å‡ºé”™: {e}"
                        print(f"âš ï¸  {error_msg}")
                        self.migration_stats['errors'].append(error_msg)
                        continue
            
            # æ‰¹é‡ä¿å­˜åˆ°æ•°æ®åº“
            if books_data:
                saved_count = await self.book_repo.save_books(books_data)
                self.migration_stats['books_migrated'] = saved_count
                print(f"âœ… æˆåŠŸè¿ç§» {saved_count} æ¡ä¹¦ç±è®°å½•")
            else:
                print("ğŸ“ æ²¡æœ‰æ•°æ®éœ€è¦è¿ç§»")
                
        except Exception as e:
            error_msg = f"è¿ç§»ä¹¦ç±æ•°æ®å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self.migration_stats['errors'].append(error_msg)
    
    async def migrate_api_sales_data(self):
        """è¿ç§»APIé”€å”®æ•°æ® (api_sales_data.csv)"""
        csv_file = "api_sales_data.csv"
        print(f"\nğŸ’° è¿ç§»APIé”€å”®æ•°æ®: {csv_file}")
        
        if not Path(csv_file).exists():
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
            return
        
        try:
            sales_data = []
            
            with open(csv_file, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                
                for row_num, row in enumerate(reader, 1):
                    try:
                        sale_data = {
                            'book_isbn': row.get('book_isbn', ''),
                            'sale_date': row.get('sale_date', ''),
                            'sold_time': row.get('sold_time', ''),
                            'price': float(row.get('price', 0)) if row.get('price') else None,
                            'quality': row.get('quality', ''),
                            'analyzed_at': row.get('analyzed_at', ''),
                        }
                        sales_data.append(sale_data)
                        
                    except Exception as e:
                        error_msg = f"å¤„ç†ç¬¬{row_num}è¡Œé”€å”®æ•°æ®æ—¶å‡ºé”™: {e}"
                        print(f"âš ï¸  {error_msg}")
                        self.migration_stats['errors'].append(error_msg)
                        continue
            
            # æ‰¹é‡ä¿å­˜åˆ°æ•°æ®åº“
            if sales_data:
                saved_count = await self.sales_repo.save_sales_data(sales_data)
                self.migration_stats['api_sales_migrated'] = saved_count
                print(f"âœ… æˆåŠŸè¿ç§» {saved_count} æ¡APIé”€å”®è®°å½•")
            else:
                print("ğŸ“ æ²¡æœ‰é”€å”®æ•°æ®éœ€è¦è¿ç§»")
                
        except Exception as e:
            error_msg = f"è¿ç§»APIé”€å”®æ•°æ®å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self.migration_stats['errors'].append(error_msg)
    
    async def migrate_sales_stats_data(self):
        """è¿ç§»é”€å”®ç»Ÿè®¡æ•°æ® (book_sales.csv)"""
        csv_file = "book_sales.csv"
        print(f"\nğŸ“ˆ è¿ç§»é”€å”®ç»Ÿè®¡æ•°æ®: {csv_file}")
        
        if not Path(csv_file).exists():
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
            return
        
        try:
            # è¿™é‡Œå¯ä»¥å®ç°å…·ä½“çš„é”€å”®ç»Ÿè®¡æ•°æ®è¿ç§»é€»è¾‘
            # ç›®å‰åªæ˜¯è¯»å–å¹¶ç»Ÿè®¡
            stats_count = 0
            
            with open(csv_file, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    stats_count += 1
            
            self.migration_stats['sales_stats_migrated'] = stats_count
            print(f"âœ… ç»Ÿè®¡äº† {stats_count} æ¡é”€å”®ç»Ÿè®¡è®°å½•")
            
        except Exception as e:
            error_msg = f"è¿ç§»é”€å”®ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self.migration_stats['errors'].append(error_msg)
    
    async def verify_migration(self):
        """éªŒè¯è¿ç§»ç»“æœ"""
        print(f"\nğŸ” éªŒè¯è¿ç§»ç»“æœ...")
        
        try:
            # è·å–å·²å­˜åœ¨çš„itemidæ•°é‡æ¥éªŒè¯ä¹¦ç±æ•°æ®
            existing_itemids = await self.book_repo.get_existing_itemids()
            db_books_count = len(existing_itemids)
            
            print(f"ğŸ“š æ•°æ®åº“ä¸­çš„ä¹¦ç±è®°å½•æ•°: {db_books_count}")
            
            if db_books_count > 0:
                print("âœ… ä¹¦ç±æ•°æ®è¿ç§»éªŒè¯é€šè¿‡")
            else:
                print("âš ï¸  æ•°æ®åº“ä¸­æ²¡æœ‰ä¹¦ç±æ•°æ®")
            
        except Exception as e:
            error_msg = f"éªŒè¯è¿ç§»ç»“æœå¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self.migration_stats['errors'].append(error_msg)
    
    def print_migration_summary(self):
        """æ‰“å°è¿ç§»æ‘˜è¦"""
        print("\n" + "="*50)
        print("ğŸ“Š è¿ç§»ç»“æœæ‘˜è¦")
        print("="*50)
        
        print(f"ğŸ“š ä¹¦ç±è®°å½•è¿ç§»: {self.migration_stats['books_migrated']} æ¡")
        print(f"ğŸ’° APIé”€å”®è®°å½•è¿ç§»: {self.migration_stats['api_sales_migrated']} æ¡")
        print(f"ğŸ“ˆ é”€å”®ç»Ÿè®¡è®°å½•: {self.migration_stats['sales_stats_migrated']} æ¡")
        
        if self.migration_stats['errors']:
            print(f"\nâš ï¸  è¿ç§»è¿‡ç¨‹ä¸­çš„é”™è¯¯ ({len(self.migration_stats['errors'])} ä¸ª):")
            for i, error in enumerate(self.migration_stats['errors'], 1):
                print(f"  {i}. {error}")
        else:
            print(f"\nâœ… è¿ç§»è¿‡ç¨‹æ— é”™è¯¯")
        
        print("="*50)
    
    async def backup_csv_files(self):
        """å¤‡ä»½åŸå§‹CSVæ–‡ä»¶"""
        print("\nğŸ’¾ å¤‡ä»½åŸå§‹CSVæ–‡ä»¶...")
        
        csv_files = ["books_data.csv", "api_sales_data.csv", "book_sales.csv"]
        backup_dir = Path("csv_backup")
        backup_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        for csv_file in csv_files:
            if Path(csv_file).exists():
                backup_file = backup_dir / f"{Path(csv_file).stem}_{timestamp}.csv"
                try:
                    import shutil
                    shutil.copy2(csv_file, backup_file)
                    print(f"  âœ… å·²å¤‡ä»½: {csv_file} -> {backup_file}")
                except Exception as e:
                    print(f"  âŒ å¤‡ä»½å¤±è´¥: {csv_file} - {e}")

class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å·¥å…·"""
    
    def __init__(self, db_path: str = "sellbook.db"):
        self.db_path = db_path
    
    async def show_database_info(self):
        """æ˜¾ç¤ºæ•°æ®åº“ä¿¡æ¯"""
        print(f"ğŸ“Š æ•°æ®åº“ä¿¡æ¯: {self.db_path}")
        print("="*40)
        
        if not Path(self.db_path).exists():
            print("âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
            return
        
        try:
            import aiosqlite
            
            async with aiosqlite.connect(self.db_path) as db:
                # è·å–æ‰€æœ‰è¡¨ä¿¡æ¯
                cursor = await db.execute("""
                    SELECT name FROM sqlite_master 
                    WHERE type='table' AND name NOT LIKE 'sqlite_%'
                """)
                tables = await cursor.fetchall()
                
                print(f"ğŸ“‹ æ•°æ®è¡¨æ•°é‡: {len(tables)}")
                
                for table_name, in tables:
                    cursor = await db.execute(f"SELECT COUNT(*) FROM {table_name}")
                    count = await cursor.fetchone()
                    print(f"  ğŸ“Š {table_name}: {count[0]} æ¡è®°å½•")
                
                # æ•°æ®åº“æ–‡ä»¶å¤§å°
                db_size = Path(self.db_path).stat().st_size
                print(f"ğŸ’¾ æ•°æ®åº“æ–‡ä»¶å¤§å°: {db_size / 1024:.1f} KB")
                
        except Exception as e:
            print(f"âŒ è·å–æ•°æ®åº“ä¿¡æ¯å¤±è´¥: {e}")
        
        print("="*40)

async def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "info":
        # æ˜¾ç¤ºæ•°æ®åº“ä¿¡æ¯
        db_manager = DatabaseManager()
        await db_manager.show_database_info()
        return
    
    # æ‰§è¡Œæ•°æ®è¿ç§»
    migrator = DatabaseMigrator()
    
    # å¯é€‰ï¼šå¤‡ä»½CSVæ–‡ä»¶
    await migrator.backup_csv_files()
    
    # æ‰§è¡Œè¿ç§»
    await migrator.migrate_all()

if __name__ == "__main__":
    print("ğŸ“¦ CSVåˆ°SQLiteæ•°æ®åº“è¿ç§»å·¥å…·")
    print("ä½¿ç”¨æ–¹æ³•:")
    print("  python migrate_to_database.py        # æ‰§è¡Œæ•°æ®è¿ç§»")
    print("  python migrate_to_database.py info   # æŸ¥çœ‹æ•°æ®åº“ä¿¡æ¯")
    print()
    
    asyncio.run(main())